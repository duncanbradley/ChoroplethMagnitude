---
title: "Choropleth Maps Can Convey Magnitude Through the Range of the Accompanying Color Legend"

# useful stuff here:  https://quarto.org/docs/reference/cells/cells-knitr.html#cache 
knitr:
  opts_chunk: 
    R.options:
      knitr.graphics.auto_pdf: true

format:
  pdf: default
  tandf-pdf:
    keep-tex: true  
    
mainfont: Roboto
sansfont: Roboto

execute:
  echo: false
  warning: false
  message: false
  
author:
  - name: Duncan Bradley
    affiliations:
      - ref: PCHN
    orcid: 
    email: duncan.bradley@manchester.ac.uk
  - name: Boshuo Zhang
    affiliations:
      - ref: CS
  - name: Caroline Jay
    affiliations:
      - ref: CS
  - name: Andrew J. Stewart
    affiliations:
      - ref: CS
      
affiliations:
  - id: PCHN
    name: The University of Manchester
    department: Division of Psychology, Communication, and Human Neuroscience
    address: Oxford Road
    city: Manchester
    country: UK
    postal-code: M13 9PL
    
  - id: CS
    name: The University of Manchester
    department: Department of Computer Science
    address: Oxford Road
    city: Manchester
    country: UK
    postal-code: M13 9PL
    
abstract: |
  Data visualization software provides the ability to create highly customizable choropleth maps. This presents an abundance of design choices. The color legend, one particular aspect of choropleth map design, has the potential to effectively convey data points' magnitudes (how large or small they are). Color legends present the mapping between a specific range of colors and a specific range of numerical values. In this experiment, we demonstrate that manipulating this range affects interpretations of the magnitude of plotted values. Participants (N = 100) judged the urgency of addressing pollution levels as greater when the color legend's upper bound was equal to the maximum plotted value, compared to when it was significantly larger than the maximum plotted value. This provides insight into the cognitive processing of plotted data in choropleth maps that are designed to promote inferences about overall magnitude.

keywords: 
  - template
  - demo
  
bibliography: bibliography.bib 
csl: taylor-and-francis-harvard-x.csl #citation stylesheet

---


REDO:

```{r} 
#| label: setup
knitr::opts_chunk$set(echo = FALSE)

set.seed(45789) # seed for random number generation
knitr::opts_chunk$set(cache.extra = knitr::rand_seed) # Discard cache when random seed changes

knitr::opts_chunk$set(cache.comments = FALSE) # ignore changes to comments
```

```{r} 
#| label: load-libraries
library(tidyverse)
library(ggridges)
library(buildmer)
library(broom.mixed)
library(lme4)
library(insight)
library(papaja) 
library(magick) 
library(patchwork)
library(ggpubr)
library(kableExtra)
library(emmeans)
library(knitr)
library(effectsize)
```

```{r} 
#| label: data-wrangling
# read in the anonymized data file (created with the anonymization.R script)
anon_database <- read_csv("anon_database.csv")

# to get the data into the correct format for analysis

# extract literacy data
# calculate literacy score (sum of five responses)
literacy <- anon_database %>%
  filter(!is.na(q1_slider.response)) %>%
  rowwise() %>%
  mutate(literacy = sum(c(q1_slider.response, 
                          q2_slider.response, 
                          q3_slider.response, 
                          q4_slider.response, 
                          q5_slider.response))) %>%
  select(participant,
         literacy)

# define education categories 
edu_labels <- set_names(c('No formal qualications',
                          'Secondary education (e.g. GED/GCSE)',
                          'High school diploma/A-levels',
                          'Technical/community college',
                          'Undergraduate degree (BA/BSc/other)',
                          'Graduate degree (MA/MSc/MPhil/other)',
                          'Doctorate degree (PhD/other)',
                          'Don\'t know / not applicable'),
                        seq(8,1,-1))

# define gender categories
gender_labels <- set_names(c("Prefer not to say", 
                             "In another way:",
                             "Non-binary", 
                             "Man", 
                             "Woman"),
                           1:5)
# extract demographics
# link slider response numbers to gender categories 
# link slider response numbers to education categories
demographics <- anon_database %>%
  filter(!is.na(genderResp1.response)) %>%
  mutate(genderResp1.response = 
           recode(genderResp1.response, !!!gender_labels)) %>%
  mutate(edu_slider.response =
           recode(edu_slider.response, !!!edu_labels)) %>%
  select(participant,
         ageResp.text,
         genderResp1.response,
         edu_slider.response)

# extract duration data (in seconds)
durations <- anon_database %>%
  filter(!is.na(total_duration)) %>%
  select(participant, total_duration)

# read in map_data.csv
mapdata <- read_csv('map_data.csv') %>%
  rowwise() %>%
  mutate(max_value = max(Data1, Data2, Data3, Data4)) %>%
  select(item_no, max_value)

# select only relevant columns and rows
# then join the additional data frames created above
anon_database <- anon_database %>%
  select(participant,
         slider.response,
         scale,
         label,
         item_type,
         item_no,
         correct_option,
         AC_correct, 
         AC_no_correct, 
         AC_outcome) %>%
  filter(!is.na(item_no)) %>%
  inner_join(literacy, by = "participant") %>%
  inner_join(demographics, by = "participant") %>%
  inner_join(durations, by = "participant") %>%
  inner_join(mapdata, by = "item_no")

# recode slider.response values
# from 1-2 to 0-1
# to avoid confusion interpreting these values
anon_database <- anon_database %>%
  mutate(slider.response = slider.response - 1,
         correct_option = correct_option - 1)

# recode names of the 'label' factor to 'present' and 'absent'
anon_database <- anon_database %>%
  mutate(label = recode(label, label = "present", blank = "absent"))

# recode the levels of the 'item_type' factor, so that they can be read by R
# 'E' = experimental
# 'AC' = attention check
anon_database <- anon_database %>%
  mutate(item_type = case_when(item_no <= 48 ~ "E",
                               item_no > 48 ~ "AC"))

# convert the two experimental factors to 'factor'
anon_database <- anon_database %>%
  rename(range = scale) %>%
  mutate(across(c("range", "label"), as_factor))

# set the contrasts of the two factors to sum contrasts
contrasts(anon_database$range) <- matrix(c(.5, -.5))
contrasts(anon_database$label) <- matrix(c(.5, -.5))

# create new dataframe 'passed' 
# which includes only those who satisfied the attention check criteria
# and only includes experimental items
passed <- anon_database %>%
  filter(AC_outcome == "PASS") %>%
  filter(item_type == "E")

# create new dataframe 'passed' 
# which includes those who satisfied the attention check criteria AND those who did not
# but also only includes experimental items
both <- anon_database %>%
  filter(item_type == "E") 
```


```{r} #| label: comparison-function, include=FALSE}
# this function takes a model and creates a new model for anova comparison
# a new set of fixed effects will be specified, but the same random effects structure will be used
comparison <- function(model, fixed) {
  
  form <- formula(model)
  
  newfixed <- function(form, fixed) {

    fixedfx <-
      remove.terms(form,"placeholder") %>% # generate full formula (expand '*')
      nobars() # get formula for fixed effects only

    fixedterms <-
      terms.formula(fixedfx) %>% # get terms for fixed effects
      attr("term.labels") # get character vector of fixed effects terms

    # remove all terms to get only the response
    response <- remove.terms(fixedfx, fixedterms) %>% remove.terms(fixedterms)

    out <- add.terms(response, fixed)
    return(out)
  }
  
  getrandom <- function(form) {
    
    parens <- function(x) {paste0("(",x,")")}
    onlyBars <- function(form) {
      reformulate(
        sapply(
          findbars(form), # list of character vector for each random effect
          function(x)  parens(deparse(x))), # put each character vector in brackets
        response = form[[2]]) 
    }
    
    out <- onlyBars(form)
    return(out)
  }
  
  merge.formula <- function(form1, form2, ...){
    # adapted from https://stevencarlislewalker.wordpress.com/2012/08/06/merging-combining-adding-together-two-formula-objects-in-r/
    
    # get character strings of the names for the responses 
    # (i.e. left hand sides, lhs)
    lhs1 <- deparse(form1[[2]])
    #print(lhs1)
    lhs2 <- deparse(form2[[2]])
    #print(lhs2)
    if(lhs1 != lhs2) stop('both formulas must have the same response')
    
    # get character strings of the right hand sides
    rhs1 <- strsplit(paste(form1[3]), " \\+ ")[[1]] 
    rhs2 <- strsplit(paste(form2[3]), " \\+ ")[[1]] 
    
    # put the two sides together with the amazing 
    # reformulate function
    out <- reformulate(termlabels = c(rhs1, rhs2), 
                       response = lhs1)
    
    # set the environment of the formula (i.e. where should
    # R look for variables when data aren't specified?)
    #environment(out) <- parent.frame()
    return(out)
  }
  
  newfixedfx <- newfixed(form, fixed)
  fullranfx <- getrandom(form)
  merge.formula(newfixedfx, fullranfx)
  
}
```

```{r} #| label: anova-results-function, include=FALSE}
# this function takes two nested models, runs an anova, and the outputs the Likelihood Ratio Statistic, degrees of freedom, and p value to the global environment
anova_results <- function(test_model, full_model) {
  
  # first argument 
  test_model_name <- deparse(substitute(test_model))
  full_model_name <- deparse(substitute(full_model))

  if (class(test_model) == "buildmer") test_model <- test_model@model
  if (class(full_model) == "buildmer") full_model <- full_model@model
  
  anova_output <- anova(test_model, full_model)
  
  assign(paste0(test_model_name, ".Chi"),
         anova_output$Chisq[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".Df"),
         anova_output$Df[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".p"),
         anova_output$`Pr(>Chisq)`[2],
         envir = .GlobalEnv)
  
  es <- eta_squared(full_model) 
  
  es %>% pull(Parameter) %>%
    map(function(x) assign(paste0(full_model_name, 
                                  ".eta.", 
                                  str_replace(x, ":", "_")),
                           es %>%
                             filter(Parameter == x) %>% 
                             pull(Eta2_partial),
                           envir = .GlobalEnv))
}
```

```{r} #| label: random-str-function, include=FALSE}
# this function creates a table which displays the random effects structure (intercepts and slopes) for a given model
random_str <- function(model) {
  model <- model@model
  terms <- model %>% find_random %>% unlist() %>% unname()
  mylist <- model %>% formula %>% findbars() %>% as.character()
  slopes <- lapply(mylist, str_extract, "(?<=\\+ )(.*)(?= \\| )") %>% 
    unlist()
  tibble(terms, slopes)
}
```

```{r} #| label: print-es-function, include=FALSE}
# for dealing with effect sizes less than .001
print_es <- function(x) {ifelse(x<.01, "< 0.01", paste("=", printnum(x)))}
```

# Introduction {#sec-intro}

To make sense of statistics presented in newspaper articles or scientific reports, it is often important to interpret their meaning in context. This may involve determining whether the presented values represent large or small numbers. Data visualizations are often used to convey statistics, so understanding how these tools may communicate data points' magnitudes is crucial.

Choropleth maps employ colors to represent values and are typically used to convey spatial variability. In order to aid discrimination and facilitate identification of spatial patterns, values are often encoded using the entire range of the chosen color palette. Thus, the range of values on the accompanying color legend typically consists of only those values which were observed. However, this is not the only application for a choropleth map. In certain cases, displaying values' *absolute* magnitudes may be considered more pertinent than displaying their *relative* magnitudes. This would allow a viewer to gauge, on the whole, how large or small presented values are, in context. To communicate this, the range of values on the accompanying color legend may include values which were not observed but remain relevant nonetheless. Designers may wish to sacrifice discrimination ability for an overt display of magnitude, in order to convey their intended message.

Indeed, choropleth maps displaying overall magnitudes have been used in practice. @fig-DFP-example depicts data concerning public support for a federal ban on abortion in the U.S. The accompanying color legend presents the entire range of possible values: from 0\% to 100\% support. Since plotted values do not exceed 30\%, their magnitudes appear small, in context. In addition, whereas a typical color scale would amplify differences between regions, this design presents variability between states as low. This lends credibility to the notion that, for this aspect of a divisive issue, public support is consistently low across the U.S.



```{r}
#| label: fig-DFP-example
#| fig-cap: A choropleth map displaying data from an analysis of state-level public support for a federal ban on abortion in the U.S [@fischer_federal_2021]. The color legend employs a diverging blue-red color palette, with white in the center, showing the full range of possible values. The 30% point is marked with a dotted line and labeled to indicate that no state exceeds this level of support. Reproduced with permission.
#| fig-alt: A choropleth map of the U.S. with the title 'There is not a single state where support for a federal ban on abortion has more than 30 percent support among the public'. The color legend employs a diverging blue-red color palette, with white in the center, showing the full range of possible values. Each state is colored one of several shades of light blue. The 30 percent point is marked with a dotted line and labeled to indicate that no state exceeds this level of support.
knitr::include_graphics("examples/dfp.png")
```


This paper explores cognitive processing of overall magnitude in choropleth maps. Through an empirical study, we demonstrate that color legends, which depict the mapping between colors and numerical values, can imply whether plotted values are large or small. Even when the mapping between color and numerical value remains the same, the range of the color legend provides a crucial source of context. The relationship between this range and the plotted data influences viewers' interpretations of magnitude.

# Related Work
## Communicating Magnitude Through Data Visualization

Empirical studies in various scientific fields have explored how interpretations of magnitude are influenced by data visualization design choices. 

Recently, the practice of y-axis truncation has enjoyed attention in experiments at the intersection of the disciplines of data visualization and psychology. Y-axis truncation refers to the practice of minimizing the range of values that appear on the y-axis. This typically involves starting the y-axis at a value greater than zero [@correll_truncating_2020]. However, some experiments on y-axis truncation have employed axes that are roughly symmetrical about the plotted data [@witt_graph_2019]. Truncation effects are therefore not just associated with the exclusion of a zero value, but also the exclusion of values *above* the observed data, which make differences appear smaller. Thus, more generally, truncation effects illustrate people's treatment of axes as implicit scales for making qualitative judgements about presented data.

Research on the effects of y-axis truncation has focused on how this practice can alter people's interpretations of the magnitude of the difference between plotted values. Demonstrating the effect of y-axis truncation with a large online sample, @pandey_how_2015 found that ratings of the magnitude of the difference between values were greater when a truncated axis was used to display the difference between safe drinking water levels in two towns. In both bar charts and line charts, increasing the degree of truncation produces increasing estimations of the severity of the difference between values [@correll_truncating_2020]. Encouraging careful attention to plotted data by ensuring that numerical values are read precisely does not eliminate this effect [@correll_truncating_2020]. Warnings somewhat reduce, but do not eradicate, the difference between interpretations of truncated and non-truncated charts [@yang_truncating_2021]. Visual indicators of truncation are also ineffective [@correll_truncating_2020]. @driessen_misleading_2022 observed smaller effects, but were concerned with numerical estimates of differences between values, rather than subjective interpretations.

@witt_graph_2019 demonstrated that using the widest possible y-axis range diminishes a viewer's sensitivity, which is the ability to distinguish between different degrees of separation between values. On the other hand, using the smallest possible y-axis range increases bias in interpretation (i.e., the extent to which judgments of the magnitude of difference deviate from actual effect sizes). To maximize sensitivity and minimize bias, and to ensure correspondence between the appearance of the difference and the reality, Witt suggests using a range of 1-2 standard deviations for y-axis limits.

Witt's [@witt_graph_2019] recommendations are prescribed for disciplines which use standardized effect sizes (e.g., Cohen's d) in the reporting of data and statistics. @correll_truncating_2020 provide more general advice relevant to those in all disciplines: the appearance of differences in a visualization should be appropriate for the specific data. Therefore the decision whether or not to truncate an axis depends on the real-world magnitude of the difference, and ultimately designers should ensure they represent this faithfully. Evidence suggests that viewers interpret the axis range as a representation of the relevant numerical context within which plotted data should be assessed. When an axis only just contains a pair of values, they will generally be considered to be highly divergent. When an axis easily contains these values, they will generally be considered similar, because the difference between values will be dwarfed by the vastness of the scale. Arbitrary rules will not absolve a chart designer's responsibility to consider what their visualization implies [@correll_truncating_2020].

As @yang_truncating_2021 discuss, one explanation for these effects draws on Grice's co-operative principle [@grice_logic_1975]. This theory, originally concerning linguistic utterances, would suggest that components of a chart, such as axes, will be considered to communicate relevant information about plotted data. Thus, a viewer will derive a designer's intended message from the features of the visualization. Changing one's interpretation of magnitude in accordance with changes to axis range could therefore be considered a coherent response. 

Research on risk communication has also explored how visualization design choices affect interpretations of presented information. A set of experiments relevant to the present investigation originated with empirical data which suggested that icon arrays were more effective than text at promoting risk-averse behavior [@stone_effects_1997]. Further research [@stone_foregroundbackground_2003] suggested that this occurred because the data visualizations only displayed the number of people affected by the negative outcome. Therefore, unlike the text, the icon arrays made the numerator more salient than the denominator (the total number of people in the sample). This was demonstrated empirically in the same study, using bar charts: the difference between numerators (15 vs. 30) appeared much bigger when the larger numerator (30) was used for the upper axis limits, compared to when the denominator (5000) was used for the upper axis limits. Risk reduction (the degree of difference between plotted values) was perceived as smaller when bar charts were extended to incorporate the denominator. Unlike the above studies on y-axis truncation [@pandey_how_2015; @witt_graph_2019; @correll_truncating_2020; @yang_truncating_2021; @driessen_misleading_2022], the lower axis limit was not manipulated, and remained fixed at zero. This pattern of results has been replicated using icon arrays [@garcia-retamero_who_2010] and pie charts [@hu_foreground-background_2014], and a similar effect has been reported for line charts [@taylor_misleading_1986] suggesting this phenomenon is driven by a common mechanism independent of chart type.

Stone et al.'s [@stone_foregroundbackground_2003] experiment demonstrated that extending the upper limit caused participants to interpret the difference between values as smaller. Unfortunately, the design of this experiment leaves uncertainty as to whether this extension affected interpretations of the magnitude of *the values themselves*, because participants only compared risks between charts in the same condition, not across conditions. However, this issue was addressed by @okan_probability_2020, who found that icon arrays which *did not* display the denominator increased perceived risk relative to those which did (with larger increases at smaller probabilities). Including the denominator also resulted in more accurate estimates of the underlying risk probabilities. This accords with the finding that the apparent magnitude of risk decreases when the upper limit is extended in a risk ladder visualization [@sandman_high_1994]. This implies that interpretations of magnitude are informed, in part, by the data point's position within the risk ladder's limits.

## Encoding Values Using Color

In data visualizations employing geometric encodings (e.g., position, extent), axes are the dimensions along which data are plotted. In colormap visualizations, a different type of axis is present, which is not used to display data directly, but presents the mapping between colors and numerical values, henceforth referred to as a 'color legend'. Default settings in popular visualization tools, such as ggplot2 [@wickham_ggplot2_2016] and Matplotlib [@hunter_matplotlib_2007] tend to employ color legends which use the minimum and maximum values in the data at their extremes. Thus, the potential for values smaller than the minimum, or larger than the maximum, is not encoded by these color legends. This facilitates comparison between values, since using a wide range of colors improves discrimination ability. Crucially, however, it does not facilitate magnitude judgments. Consider, for example, a heatmap showing profits for each quarter over the course of five years. Using the darkest color on the color legend to represent the highest profits could conceal the fact that profits in general have been poor for the entirety of this period, because the color legend is agnostic towards real-world magnitude.

Research involving color legends has often focused on assessing the appropriateness of different color scales and capturing color discriminability through color difference models. @harrower_colorbrewerorg_2003 developed a tool for selecting suitable color scales for particular forms of data: sequential scales for ordinal or numerical data, qualitative scales for categorical data, and diverging scales for highlighting midpoints. Other work has identified specific features which make for an effective color scheme, from low-level properties such as uniform luminance [@dasgupta_effect_2020] to high-level properties such as consistency with semantic color associations [@lin_selecting_2013]. Researchers have also modeled the impact of mark size on color discriminability [@stone_engineering_2014] and demonstrated adaptation of color difference models to specific viewing conditions [@szafir_adapting_2014]. 

Choropleth maps are one of several types of colormap visualization which map color to numerical data (see also, heatmaps and neuroimaging visualizations). Schiewe [@schiewe_empirical_2019] illustrates that impressions of quantity are positively associated with the proportion of a choropleth map occupied by darker colors. The size of geographical regions and the binning of values can both influence the extent to which a map displays colors on the darker end of the chosen color scale, which impacts judgements of presented data. Whilst this study manipulated the appearance of plotted data in maps, other research has held the appearance of plotted data constant in order to study how the context surrounding a color legend affects viewers' inferences. @schloss_mapping_2019 observed that viewers' spontaneous interpretations of the relationship between color and quantity can depend on which background color is used. Their experiment attempted to reconcile contrasting theories about which aspects of a color stimulus are associated with greater quantities ('dark-is-more'; 'contrast-is-more'; 'opaque-is-more'). They found that viewers associate darker colors with greater quantities when there is no apparent variation in the color scale's opacity. However, when the color scale does appear to have varying degrees of opacity, an 'opaque-is-more' association prevails. For example, black-white color scales appear to have high opacity against a black background (so lighter grays are more readily associated with larger quantities), but low opacity against a blue background (so lighter grays are more readily associated with smaller quantities).

Different interpretations of the same dataset can also arise through modified displays of the same color scale. Empirical research has compared color legends which only use color features (e.g., increasing luminance and decreasing saturation) to indicate uncertainty, to color legends which also signal uncertainty through increasing reduction in the range of possible colors, termed Value-Suppressing Uncertainty Palettes (VSUPs, [@correll_value-suppressing_2018]). In Correll et al.'s study, participants played a 'Battleship' style game which involved reducing risk by balancing danger and uncertainty. Participants were more likely to favor riskier but more certain options over uncertain options when using VSUPs. Constraining the range of colors at higher uncertainty levels may have reduced the impression that these data points could represent desirable low-danger magnitudes. The experiment we report below examines directly how the range of values in a color legend affects interpretations of magnitude.

# Methodology

## Outline
The present experiment investigates the influence of color legend range on the cognitive processing of magnitude. We manipulated the color legend's upper bound, such that it was equal to the maximum plotted value (*truncated range*) or it was equal to double the maximum plotted value (*extended range*). We employ the term 'truncated' in a broad sense, referring to a scale that is constrained such that potentially relevant values are omitted, not simply a scale that excludes a zero value. Using a lower bound of zero reduced the number of differences between the two conditions, so that only the upper bound was manipulated. This also meant that plotted values' variability appeared smaller, assisting participants in judging the overall magnitude of these values. For each item, the color palette, geographic regions, and the mapping between colors and numerical values, were identical across conditions. Therefore, the only difference between versions of a given item was the arrangement of the color legend: the map itself remained unchanged.

Rather than asking participants to make abstract judgments about the size of abstract values, we presented fictitious pollution data, and asked how urgently action should be taken to address the pollution levels displayed in each data visualization. This captures participants' assessments of magnitude through the type of judgments which can drive behavior. In addition to increased ecological validity, we also anticipated that pollution data might be able to generate a balanced set of responses to the question of urgency. A variable evoking an extreme negative reaction may have elicited responses at ceiling and one too trivial may have elicited responses at floor. We expected participants to recognize that a sufficient degree of pollution would require action, but also understand that low levels may require less urgent action. We did not provide a specific definition of urgency for participants to use when making their responses. Therefore, different participants' responses may reflect different notions of urgency. However, the within-participants design accounts for individual variation. Each participant's ratings are compared against their own ratings for the alternative condition, allowing for meaningful comparison between conditions.

Pollution levels were displayed in choropleth maps, which use color encoding to display data aggregated at the level of geographic areas. Note that we do not consider the designs of choropleth maps in this experiment to reflect best practice for plotting pollution statistics. Rather, their designs were motivated by the desire to examine the role of color legends in the interpretation of magnitude. Previous research has illustrated that the size of geographical regions can influence ensemble coding in choropleth maps [@schiewe_empirical_2019]. However, we did not control for this aspect, instead we prioritized ecological validity by using maps with real geographical regions. These maps appeared identical across conditions in order to avoid this bias confounding results.

To control for the possibility that participants used the color legend's numerical labels, rather than the range of values displayed, as a reference for their magnitude judgments, we omitted the color legend's numerical labels in half of trials. This allowed us to test whether the presence of numerical labels affected the degree to which magnitude judgments were influenced by the color legend's upper bound.

## Pre-Registration

We predicted that urgency ratings would be higher for truncated legends, compared to extended legends. In addition, we planned to compare whether any difference between these two conditions was moderated by the presence or absence of numerical labels, but made no predictions about existence or direction of any main effect or interaction. Participants completed Garcia-Retamero et al.'s [@garcia-retamero_measuring_2016] Subjective Graph Literacy scale, therefore we also planned to test whether any observed effects (or lack of) could be explained by differences in data visualization literacy. This five-item scale is a quick, reliable measure that is correlated with scores on Galesic and Garcia-Retamero's [@galesic_graph_2011] test-based measure of data visualization literacy. The pre-registration, plus materials, data and analysis code are available at <https://osf.io/qe9hf/?view_only=32c420d6ef6c45b1ae2d3dc42dc6fe69>.

## Design

In each trial, we independently manipulated two aspects of the choropleth map. When the color legend had a *truncated range*, its upper bound was equal to the maximum value displayed in the map. When the color legend had an *extended range*, its upper bound was equal to double the maximum value (and the maximum value displayed in the map appeared at the legend's halfway point). Numerical labels on the color legend were either *present* or *absent*. This resulted in four unique combinations of conditions. We employed a Latin-squared design, ensuring that each participant was exposed to each combination of conditions throughout the experiment, but only saw one combination for each given map. There were a total of 54 trials (48 experimental trials, six attention check trials). Example stimuli are shown in Figure @fig-example-stimuli.


```{r}
#| label: fig-example-stimuli
#| fig-cap: "Example stimuli: six choropleth maps showing fictitious pollution data. Four color legends are displayed below each map, but only one color legend accompanied the map in each trial. Color legends with extended ranges have a maximum value equal to double the maximum plotted value (top row: 400; bottom row: 1800). Color legends with truncated ranges have a maximum value equal to the maximum plotted value in the map (top row: 200; bottom row: 900). During the experiment, all six color scales were used in conjunction with all maximum values."
#| fig-alt: "A 3x2 grid of choropleth map visualizations, in six different colors. Each has four color legends below. The color legends below the maps in the left column terminate with the same shade of color as the darkest geographical region. The color legends below the maps in the right column terminate with a much darker shade of color. Each color legend is shown with and without numerical labels."
img1 <- ggplot() + background_image(image_read("examples/supermap_top.png")) + coord_fixed(ratio = 1041/2787)
img2 <- ggplot() + background_image(image_read("examples/supermap_bottom.png")) + coord_fixed(ratio = 1041/2787)

img1 / img2 + plot_layout()
```

{{< pagebreak >}}



# References {.unnumbered}

::: {#refs}
:::

